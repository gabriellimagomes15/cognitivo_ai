{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solução Proposta - Competição DSA de Machine Learning\n",
    "# Edição Janeiro/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv('diabetes.csv', \n",
    "                   header = None, sep = \",\",\n",
    "                   names=['Pregnancy', 'Glucose', 'BloodPressure' ,'SkinfoldThickness', 'Insulin', 'BodyMassIndex', 'DiabetesPedigreeFunction', 'Age', 'Class'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima[pima.isnull().any(axis=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.isnull().values.any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise dos dados\n",
    "columns=pima.columns[:8]\n",
    "plt.subplots(figsize=(18,15))\n",
    "length=len(columns)\n",
    "for i,j in zip(columns,range(length)):\n",
    "    plt.subplot((length/2),3,j+1)\n",
    "    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "    pima[i].hist(bins=20,edgecolor='black')\n",
    "    plt.title(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de casos de diabetes\n",
    "pima1=pima[pima['Class']==1]\n",
    "columns=pima.columns[:8]\n",
    "plt.subplots(figsize=(18,15))\n",
    "length=len(columns)\n",
    "for i,j in zip(columns,range(length)):\n",
    "    plt.subplot((length/2),3,j+1)\n",
    "    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "    pima1[i].hist(bins=20,edgecolor='black')\n",
    "    plt.title(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.plot(kind= 'box' , subplots=True, layout=(3,3),figsize=(14,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima['Class'].value_counts().plot(kind='bar', figsize=(6,6))\n",
    "plt.title('pima_indians_diabetes - Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relacionamento Entre Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.boxplot(column='Insulin',by='Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.boxplot(column='Pregnancy',by='Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.boxplot(column='Glucose',by='Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "Insulin_plt = pima.groupby(pima['Insulin']).Class.count().reset_index()\n",
    "sns.distplot(pima[pima.Class == 0]['Insulin'], color='red', kde=False, label='Diabetic')\n",
    "sns.distplot(pima[pima.Class == 1]['Insulin'], color='green', kde=False, label='Non-Diabetic')\n",
    "plt.legend()\n",
    "plt.title('Histogram of Insulin values depending in the class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "glucose_plt = pima.groupby('Glucose').Class.mean().reset_index()\n",
    "sns.barplot(glucose_plt.Glucose, glucose_plt.Class)\n",
    "plt.title('Percentual de chance de ser diagnosticado com diabetes por leitura de glicose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pima.corr()\n",
    "_ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
    "cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "_ = sns.heatmap(corr, cmap = cmap, square=True, cbar_kws={ 'shrink' : .9 }, ax=ax, annot = True, annot_kws = {'fontsize' : 12 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(pima,hue='Class',palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for zero values\n",
    "print(\"Number of missing values : \" + repr(pima[pima.Glucose == 0].shape[0]))\n",
    "print(pima[pima.Glucose == 0].groupby('Class')['Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero value with the mean value of the classes\n",
    "Glucose_0 = pima[(pima['Glucose']== 0)]\n",
    "pima[(pima['Glucose']== 0) & (pima['Class'] == 0)] = Glucose_0[Glucose_0['Class']== 0].replace(0, pima[(pima['Class']== 0)].mean())\n",
    "pima[(pima['Glucose']== 0) & (pima['Class'] == 1)] = Glucose_0[Glucose_0['Class']== 1].replace(0, pima[(pima['Class']== 1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero values\n",
    "print(\"Number of missing values : \" + repr(pima[pima.BloodPressure == 0].shape[0]))\n",
    "print(pima[pima.BloodPressure == 0].groupby('Class')['Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero value with the mean value of the classes\n",
    "BloodPressure_0 = pima[(pima['BloodPressure']== 0)]\n",
    "pima[(pima['BloodPressure']== 0) & (pima['Class'] == 0)] = BloodPressure_0[BloodPressure_0['Class']== 0].replace(0, pima[(pima['Class']== 0)].mean())\n",
    "pima[(pima['BloodPressure']== 0) & (pima['Class'] == 1)] = BloodPressure_0[BloodPressure_0['Class']== 1].replace(0, pima[(pima['Class']== 1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero values\n",
    "print(\"Number of missing values : \" + repr(pima[pima.SkinfoldThickness == 0].shape[0]))\n",
    "print(pima[pima.SkinfoldThickness == 0].groupby('Class')['Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero value with the mean value of the classes\n",
    "SkinfoldThickness_0 = pima[(pima['SkinfoldThickness']== 0)]\n",
    "pima[(pima['SkinfoldThickness']== 0) & (pima['Class'] == 0)] = SkinfoldThickness_0[SkinfoldThickness_0['Class']== 0].replace(0, pima[(pima['Class']== 0)].mean())\n",
    "pima[(pima['SkinfoldThickness']== 0) & (pima['Class'] == 1)] = SkinfoldThickness_0[SkinfoldThickness_0['Class']== 1].replace(0, pima[(pima['Class']== 1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero values\n",
    "print(\"Number of abnormal cases in skinfold thickness : \" + repr(pima[pima.SkinfoldThickness > 60].shape[0]))\n",
    "print(pima[pima.SkinfoldThickness > 60]['SkinfoldThickness'])\n",
    "print(pima[pima.SkinfoldThickness > 60].groupby('Class')['Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing impossible value with mean value\n",
    "pima['SkinfoldThickness'].iloc[579] = pima['SkinfoldThickness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero values\n",
    "print(\"Number of missing values : \" + repr(pima[pima.Insulin == 0].shape[0]))\n",
    "print(pima[pima.Insulin == 0].groupby('Class')['Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero value with the mean value of the classes\n",
    "Insulin_0 = pima[(pima['Insulin']== 0)]\n",
    "pima[(pima['Insulin']== 0) & (pima['Class'] == 0)] = Insulin_0[Insulin_0['Class']== 0].replace(0, pima[(pima['Class']== 0)].mean())\n",
    "pima[(pima['Insulin']== 0) & (pima['Class'] == 1)] = Insulin_0[Insulin_0['Class']== 1].replace(0, pima[(pima['Class']== 1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero values\n",
    "print(\"Number of missing values : \" + repr(pima[pima.BodyMassIndex == 0].shape[0]))\n",
    "print(pima[pima.BodyMassIndex == 0].groupby('Class')['Class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero value with the mean value of the classes\n",
    "BodyMassIndex_0 = pima[(pima['BodyMassIndex']== 0)] \n",
    "pima[(pima['BodyMassIndex']== 0) & (pima['Class'] == 0)] = BodyMassIndex_0[BodyMassIndex_0['Class']== 0].replace(0, pima[(pima['Class']== 0)].mean())\n",
    "pima[(pima['BodyMassIndex']== 0) & (pima['Class'] == 1)] = BodyMassIndex_0[BodyMassIndex_0['Class']== 1].replace(0, pima[(pima['Class']== 1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=pima.columns[:8]\n",
    "plt.subplots(figsize=(18,15))\n",
    "length=len(columns)\n",
    "for i,j in zip(columns,range(length)):\n",
    "    plt.subplot((length/2),3,j+1)\n",
    "    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "    pima[i].hist(bins=20,edgecolor='black')\n",
    "    plt.title(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.plot(kind= 'box' , subplots=True, layout=(3,3),figsize=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=12342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pima.copy().iloc[:, 0:8].values\n",
    "#target = pima.copy().iloc[:, 8:9].Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn\n",
    "import imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "# Obs: pode ser necessário reiniciar o Jupyter para poder carregar o pacote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling data is given with a subscript of 'o'\n",
    "np.random.seed(75)\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "data_o, target_o = SMOTE().fit_sample(pima, pima.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.Counter(target_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo_train, Xo_test, yo_train, yo_test = train_test_split(data_o, target_o, test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pima[pima.columns[:8]]\n",
    "target=pima['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "cols = data.iloc[:, 0:8].columns\n",
    "data[cols] = scaler.fit_transform(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[cols] = preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(pima,test_size=0.20,random_state=437,stratify=pima['Class'])# stratify the outcome\n",
    "\n",
    "X_train=train[train.columns[:8]]\n",
    "X_test=test[test.columns[:8]]\n",
    "y_train=train['Class']\n",
    "y_test=test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(Xo_train, yo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(Xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print (confusion_matrix(yo_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(yo_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data_on = preprocessing.scale(data_o)\n",
    "Xon_train, Xon_test, yon_train, yon_test = train_test_split(data_on, target_o, test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(Xon_train, yon_train)\n",
    "pred = knn.predict(Xon_test)\n",
    "\n",
    "print (confusion_matrix(yon_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(yon_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-value Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(Xo_train,yo_train)\n",
    "    pred_i = knn.predict(Xo_test)\n",
    "    error_rate.append(np.mean(pred_i != yo_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "função de peso usada na previsão. Valores possíveis:\n",
    "\n",
    "\"Uniforme\": pesos uniformes. Todos os pontos em cada neighborhood são ponderados igualmente.\n",
    "‘Distância’: pontos de ponderação pelo inverso da distância. Nesse caso, os vizinhos mais próximos de um ponto de consulta terão uma influência maior do que os vizinhos mais distantes.\n",
    "(callable): uma função definida pelo usuário que aceita uma matriz de distâncias e retorna uma matriz da mesma forma que contém os pesos.\n",
    "\n",
    "Parâmetro de potência para a métrica Minkowski. Quando p = 1, isso equivale a usar manhattan_distance (l1) e euclidean_distance (l2) para p = 2. Para p arbitrário, minkowski_distance (l_p) é usado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WITH K=1\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='distance',p=1)\n",
    "\n",
    "knn.fit(Xo_train,yo_train)\n",
    "pred = knn.predict(Xo_test)\n",
    "\n",
    "print('WITH K=1')\n",
    "print('\\n')\n",
    "print('Confusion Matrix')\n",
    "cm_knn = confusion_matrix(yo_test,pred)\n",
    "print(cm_knn)\n",
    "print('\\n')\n",
    "rpt_knn = classification_report(yo_test,pred)\n",
    "print(rpt_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de recursos usando o método Hill climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_MaxScore = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_Ind_Random = shuffle(range(0,col_num), random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = data.values[:, new_Ind]\n",
    "    Xs_train, Xs_test, ys_train, ys_test = train_test_split(newData, target, test_size=0.2, random_state=1987)\n",
    "    clf = KNeighborsClassifier(1)\n",
    "    fit = clf.fit(Xs_train, ys_train)\n",
    "    cur_Score = clf.score(Xs_test, ys_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print (\"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "error_rate = []\n",
    "random_state=19\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(Xs_train,ys_train)\n",
    "    pred_i = knn.predict(Xs_test)\n",
    "    error_rate.append(np.mean(pred_i != ys_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9, weights='distance',p=1)\n",
    "\n",
    "knn.fit(Xs_train,ys_train)\n",
    "pred = knn.predict(Xs_test)\n",
    "\n",
    "print('WITH K=31')\n",
    "print('\\n')\n",
    "print('Confusion Matrix')\n",
    "cm_knn = confusion_matrix(ys_test,pred)\n",
    "print(cm_knn)\n",
    "print('\\n')\n",
    "rpt_knn = classification_report(ys_test,pred)\n",
    "print(rpt_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN without SMOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30, weights='distance',p=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=31')\n",
    "print('\\n')\n",
    "print('Confusion Matrix')\n",
    "cm_knn = confusion_matrix(y_test,pred)\n",
    "print(cm_knn)\n",
    "print('\\n')\n",
    "rpt_knn = classification_report(y_test,pred)\n",
    "print(rpt_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "random_state=234\n",
    "dtree = DecisionTreeClassifier(random_state=998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dtree.predict(X_test)\n",
    "print(\"Accuracy for Decision treeclassifier is\",metrics.accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "cm_dtree = confusion_matrix(y_test,pred)\n",
    "print(cm_dtree)\n",
    "print('\\n')\n",
    "rpt_dtree = classification_report(y_test,pred)\n",
    "print(rpt_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn import tree\n",
    "\n",
    "dot_data = tree.export_graphviz(dtree, out_file='tree.dot', \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = pima.copy().iloc[:, 0:8].columns\n",
    "targ_names = ['Yes','No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso tenha erro com o graphviz, você deve configurá-lo no seu SO:\n",
    "\n",
    "https://stackoverflow.com/questions/35064304/runtimeerror-make-sure-the-graphviz-executables-are-on-your-systems-path-aft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import os\n",
    "from sklearn import tree\n",
    "os.environ[\"PATH\"] += os.pathsep + path\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "\n",
    "import graphviz\n",
    "\n",
    "data1 = export_graphviz(dtree,out_file=None,feature_names=feat_names,class_names=targ_names,   \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(data1)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of base decision tree estimators\n",
    "n_est = 100\n",
    "# maximum depth of any given decision tree estimator\n",
    "max_depth = 5\n",
    "# random state variable\n",
    "rstate = 42\n",
    "# initialize a random forest algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_est, \n",
    "                             max_depth=max_depth,\n",
    "                             random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "cm_rf = confusion_matrix(y_test,pred)\n",
    "print(cm_rf)\n",
    "print('\\n')\n",
    "rpt_rf = classification_report(y_test,pred)\n",
    "print(rpt_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to be used for training each model\n",
    "features = [col for col in list(X_train) ]\n",
    "print('%i features: %s' % (len(features), features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the most important featuers for predicting each target\n",
    "\n",
    "# collect ranking of most \"important\" features for E\n",
    "importances =  rf.feature_importances_\n",
    "descending_indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = [importances[idx] for idx in descending_indices]\n",
    "sorted_features = [features[idx] for idx in descending_indices]\n",
    "print('Most important feature for diabetes energy is %s' % sorted_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature importances\n",
    "\n",
    "def plot_importances(X_train, sorted_features, sorted_importances):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train (nd-array) - feature matrix of shape (number samples, number features)\n",
    "        sorted_features (list) - feature names (str)\n",
    "        sorted_importances (list) - feature importances (float)\n",
    "    Returns:\n",
    "        matplotlib bar chart of sorted importances\n",
    "    \"\"\"\n",
    "    axis_width = 1.5\n",
    "    maj_tick_len = 6\n",
    "    fontsize = 14\n",
    "    bar_color = 'lightblue'\n",
    "    align = 'center'\n",
    "    label = '__nolegend__'\n",
    "    ax = plt.bar(range(X_train.shape[1]), sorted_importances,\n",
    "                 color=bar_color, align=align, label=label)\n",
    "    ax = plt.xticks(range(X_train.shape[1]), sorted_features, rotation=90)\n",
    "    ax = plt.xlim([-1, X_train.shape[1]])\n",
    "    ax = plt.ylabel('Feature Importance', fontsize=fontsize)\n",
    "    ax = plt.tick_params('both', length=maj_tick_len, width=axis_width, \n",
    "                         which='major', right=True, top=True)\n",
    "    ax = plt.xticks(fontsize=fontsize)\n",
    "    ax = plt.yticks(fontsize=fontsize)\n",
    "    ax = plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(10,8))\n",
    "\n",
    "ax = plot_importances(X_train, sorted_features, sorted_importances)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "classifier=['Decision Tree','Random Forest','KNN','KNN (Smote)']\n",
    "models=[DecisionTreeClassifier(random_state=998),RandomForestClassifier(n_estimators=n_est, \n",
    "                             max_depth=max_depth,\n",
    "                             random_state=rstate),KNeighborsClassifier(n_neighbors=6),\"SMOTE\"]\n",
    "for i in models:\n",
    "    model = i\n",
    "    if model == \"SMOTE\":\n",
    "        model = KNeighborsClassifier(n_neighbors=1,weights='distance',p=1)\n",
    "        model.fit(Xo_train,yo_train)\n",
    "        pred1=model.predict(Xo_test)\n",
    "        temp.append(metrics.accuracy_score(pred1,yo_test))\n",
    "    else:\n",
    "        model.fit(X_train,y_train)\n",
    "        prediction=model.predict(X_test)    \n",
    "        temp.append(metrics.accuracy_score(prediction,y_test))\n",
    "        \n",
    "models_dataframe=pd.DataFrame(temp,index=classifier)   \n",
    "models_dataframe.columns=['Accuracy']\n",
    "models_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Apenas as Features Mais Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab2=pima[['Pregnancy','Glucose','SkinfoldThickness','Insulin','BodyMassIndex','Age','Class']]\n",
    "\n",
    "train1,test1=train_test_split(diab2,test_size=0.20,random_state=437,stratify=diab2['Class'])\n",
    "\n",
    "X_train=train1[train1.columns[:6]]\n",
    "X_test=test1[test1.columns[:6]]\n",
    "y_train=train1['Class']\n",
    "y_test=test1['Class']\n",
    "\n",
    "# SMOTE\n",
    "np.random.seed(795)\n",
    "data1, target1 = SMOTE().fit_sample(diab2, diab2.Class)\n",
    "Xo_train, Xo_test, yo_train, yo_test = train_test_split(data1, target1, test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "classifier=['Decision Tree','Random Forest','KNN','KNN (Smote)']\n",
    "models=[DecisionTreeClassifier(random_state=998),RandomForestClassifier(n_estimators=n_est, \n",
    "                             max_depth=max_depth,\n",
    "                             random_state=rstate),KNeighborsClassifier(n_neighbors=6),\"SMOTE\"]\n",
    "for i in models:\n",
    "    model = i\n",
    "    if model == \"SMOTE\":\n",
    "        model = KNeighborsClassifier(n_neighbors=1,weights='distance',p=1)\n",
    "        model.fit(Xo_train,yo_train)\n",
    "        pred1=model.predict(Xo_test)\n",
    "        temp.append(metrics.accuracy_score(pred1,yo_test))\n",
    "    else:\n",
    "        model.fit(X_train,y_train)\n",
    "        prediction=model.predict(X_test)    \n",
    "        temp.append(metrics.accuracy_score(prediction,y_test))\n",
    "        \n",
    "models_dataframe=pd.DataFrame(temp,index=classifier)   \n",
    "models_dataframe.columns=['Accuracy']\n",
    "models_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "kfold = KFold(n_splits=10, random_state=998) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "accuracy=[]\n",
    "classifiers=['KNN','KNN (SMOTE)','Decision Tree','Random Forest']\n",
    "models=[KNeighborsClassifier(n_neighbors=6),\"SMOTE\", DecisionTreeClassifier(),RandomForestClassifier(n_estimators=n_est, \n",
    "                             max_depth=max_depth,\n",
    "                             random_state=938)]\n",
    "for i in models:\n",
    "    model = i\n",
    "    \n",
    "    if model == \"SMOTE\":\n",
    "        model = KNeighborsClassifier(n_neighbors=1,weights='distance',p=1)\n",
    "        cv_result = cross_val_score(model,data_o,target_o, cv = kfold,scoring = \"accuracy\")\n",
    "        temp.append(cv_result.mean())\n",
    "        accuracy.append(cv_result)\n",
    "       \n",
    "    else:\n",
    "        cv_result = cross_val_score(model,data,target, cv = kfold,scoring = \"accuracy\")\n",
    "        temp.append(cv_result.mean())\n",
    "        accuracy.append(cv_result)\n",
    "new_models_dataframe2=pd.DataFrame(temp,index=classifiers)   \n",
    "new_models_dataframe2.columns=['CV Mean']    \n",
    "new_models_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box=pd.DataFrame(accuracy,index=[classifiers])\n",
    "fig3 = plt.figure(1, figsize=(12,8))\n",
    "sns.boxplot(data=box.T, orient=\"h\", palette=\"Set1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Tuning for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(random_state = 82)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Tuning for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(dtree.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_state=294\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dtree = DecisionTreeClassifier()\n",
    "random_state=194\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "dtree_random = RandomizedSearchCV(estimator = dtree, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=294, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "dtree_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model =  DecisionTreeClassifier(min_samples_leaf=2, min_samples_split=3,random_state=474)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(base_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtree_random = dtree_random.best_estimator_\n",
    "best_dtree_random.fit(X_train, y_train)\n",
    "random_accuracy = evaluate(best_dtree_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtree_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(best_dtree_random, out_file='tree2.dot', \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "accuracy=[]\n",
    "classifiers=['KNN','KNN (SMOTE)','Decision Tree','Random Forest']\n",
    "models=[KNeighborsClassifier(n_neighbors=6),\"SMOTE\", best_dtree_random,best_random]\n",
    "for i in models:\n",
    "    model = i\n",
    "    \n",
    "    if model == \"SMOTE\":\n",
    "        model = KNeighborsClassifier(n_neighbors=1,weights='distance',p=1)\n",
    "        cv_result = cross_val_score(model,data_o,target_o, cv = kfold,scoring = \"accuracy\")\n",
    "        temp.append(cv_result.mean())\n",
    "        accuracy.append(cv_result)\n",
    "       \n",
    "    else:\n",
    "        cv_result = cross_val_score(model,data,target, cv = kfold,scoring = \"accuracy\")\n",
    "        temp.append(cv_result.mean())\n",
    "        accuracy.append(cv_result)\n",
    "new_models_dataframe2=pd.DataFrame(temp,index=classifiers)   \n",
    "new_models_dataframe2.columns=['CV Mean']    \n",
    "new_models_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box=pd.DataFrame(accuracy,index=[classifiers])\n",
    "fig3 = plt.figure(1, figsize=(12,8))\n",
    "sns.boxplot(data=box.T, orient=\"h\", palette=\"Set1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim\n",
    "# Obrigado\n",
    "# www.datascienceacademy.com.br"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
